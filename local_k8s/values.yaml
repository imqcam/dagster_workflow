####################################################################################################
# User Code Deployments: Configuration for user code containers to be loaded via GRPC server. For
# each item in the "deployments" list, a K8s Deployment and K8s Service will be created to run the
# GRPC server that the Dagster webserver communicates with to get definitions information and the current
# image information. These deployments can be updated independently of the Dagster webserver, and the webserver
# will pull the current image for all execution. When using a distributed executor (such as
# Celery-K8s) for job execution, the current image will be queried once and used for all
# op executions for that run. In order to guarantee that all op executions within a job
# execution use the same image, we recommend using a unique tag (ie not "latest").
#
# All user code will be invoked within the images.
####################################################################################################
dagster-user-deployments:
  # Creates a workspace file with the gRPC servers hosting your user code.
  enabled: true

  # If you plan on deploying user code in a separate Helm release, set this to false.
  enableSubchart: true

  # Specify secrets to run user code server containers based on images in private registries. See:
  # https://kubernetes.io/docs/concepts/containers/images/#referring-to-an-imagepullsecrets-on-a-pod
  imagePullSecrets: []

  # List of unique deployments
  deployments:
    - name: "imqcam-example-1"
      image:
        # When a tag is not supplied, it will default as the Helm chart version.
        repository: "docker.io/openmsi/testing_k8s_dagster"
        tag: latest

        # Change with caution! If you're using a fixed tag for pipeline run images, changing the
        # image pull policy to anything other than "Always" will use a cached/stale image, which is
        # almost certainly not what you want.
        pullPolicy: Always

      # Arguments to `dagster api grpc`.
      # Ex: "dagster api grpc -m dagster_test.test_project.test_jobs.repo -a define_demo_execution_repo"
      # would translate to:
      # dagsterApiGrpcArgs:
      #   - "-m"
      #   - "dagster_test.test_project.test_jobs.repo"
      #   - "-a"
      #   - "define_demo_execution_repo"
      #
      # The `dagsterApiGrpcArgs` key can also be replaced with `codeServerArgs` to use a new
      # experimental `dagster code-server start` command instead of `dagster api grpc`, which takes
      # identical arguments but can reload its definitions from within the Dagster UI without
      # needing to restart the user code deployment pod.
      dagsterApiGrpcArgs:
        - "--module-name"
        - "imqcam"
        - "--attribute"
        - "defs"
      port: 3030

      # Whether or not to include configuration specified for this user code deployment in the pods
      # launched for runs from that deployment
      includeConfigInLaunchedRuns:
        enabled: true

      # Additional environment variables to set.
      # These will be directly applied to the daemon container. See
      # https://kubernetes.io/docs/tasks/inject-data-application/define-environment-variable-container/
      #
      # Example:
      #
      # env:
      # - name: ENV_ONE
      #   value: "one"
      # - name: ENV_TWO
      #   value: "two"
      env: []

      # Additional environment variables can be retrieved and set from ConfigMaps. See:
      # https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#configure-all-key-value-pairs-in-a-configmap-as-container-environment-variables
      #
      # Example:
      #
      # envConfigMaps:
      #   - name: config-map
      envConfigMaps: []

      # Additional environment variables can be retrieved and set from Secrets. See:
      # https://kubernetes.io/docs/concepts/configuration/secret/#use-case-as-container-environment-variables
      #
      # Example:
      #
      # envSecrets:
      #   - name: secret
      envSecrets: []

      # Additional labels that should be included. See:
      # https://kubernetes.io/docs/concepts/overview/working-with-objects/labels
      #
      # Example:
      # labels:
      #   my-label-key: my_label-value
      labels: {}

      # Additional volumes that should be included. See:
      # https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volume-v1-core
      #
      # Example:
      #
      # volumes:
      #   - name: my-volume
      #     configMap: my-config-map
      volumes:
        - name: imqcam-local-data
          persistentVolumeClaim:
            claimName: imqcam-local-data

      # Additional volume mounts that should be included. See:
      # See: https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volumemount-v1-core
      #
      # Example:
      #
      # volumeMounts:
      #   - name: test-volume
      #     mountPath: /opt/dagster/test_folder
      #     subPath: test_file.yaml
      volumeMounts:
        - name: imqcam-local-data
          mountPath: /tmp/imqcam_local_data

      # Init containers to run before the main container. See:
      # https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
      initContainers: []

      # Additional containers (i.e. sidecars) to run alongside the main container. See:
      # https://kubernetes.io/docs/concepts/workloads/pods/sidecar-containers/
      #
      # Example:
      #
      # sidecarContainers:
      #   - name: my-sidecar
      #     image: ...
      #     volumeMounts: []
      #     env: []
      sidecarContainers: []

      annotations: {}
      nodeSelector: {}
      affinity: {}
      tolerations: []
      podSecurityContext: {}
      securityContext: {}
      resources: {}

      # Override the default K8s scheduler
      # schedulerName: ~

      # Readiness probe detects when the pod is ready to serve requests.
      # https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes
      readinessProbe:
        # Readiness probes are enabled by default.
        enabled: true
        # If `readinessProbe` has no `exec` field, then the following default will be used:
        # exec:
        #   command: ["dagster", "api", "grpc-health-check", "-p", "{{ $deployment.port }}"]
        periodSeconds: 20
        timeoutSeconds: 10
        successThreshold: 1
        # Allow roughly 300 seconds to start up by default
        failureThreshold: 1

      # As of 0.14.0, liveness probes are disabled by default. If you want to enable them, it's recommended to also
      # enable startup probes.
      livenessProbe: {}
      startupProbe:
        enabled: false

      service:
        annotations: {}

####################################################################################################
# Run Launcher: Configuration for run launcher
####################################################################################################
runLauncher:
  # Type can be one of [K8sRunLauncher, CeleryK8sRunLauncher, CustomRunLauncher]
  type: CeleryK8sRunLauncher # K8sRunLauncher

  config:
    # This configuration will only be used if the CeleryK8sRunLauncher is selected
    celeryK8sRunLauncher:
      # Change with caution! If you're using a fixed tag for pipeline run images, changing the
      # image pull policy to anything other than "Always" will use a cached/stale image, which is
      # almost certainly not what you want.
      imagePullPolicy: "Always"

      # The Celery workers can be deployed with a fixed image (no user code included)
      image:
        # When a tag is not supplied for a Dagster provided image,
        # it will default as the Helm chart version.
        repository: "docker.io/dagster/dagster-celery-k8s"
        tag: ~
        pullPolicy: Always

      # The Kubernetes namespace where new jobs will be launched.
      # By default, the release namespace is used.
      jobNamespace: ~

      # Support overriding the name prefix of Celery worker pods
      nameOverride: "celery-workers"

      # Additional config options for Celery, applied to all queues.
      # These can be overridden per-queue below.
      # For available options, see:
      # https://docs.celeryq.dev/en/stable/userguide/configuration.html
      configSource: {}

      # Additional Celery worker queues can be configured here. When overriding, be sure to
      # provision a "dagster" worker queue, as this is the default queue used by Dagster.
      #
      # Optionally, labels and node selectors can be set on the Celery queue's workers.
      # Specifying a queue's node selector will override any existing node selector defaults.
      # configSource will be merged with the shared configSource above.
      workerQueues:
        - name: "dagster"
          replicaCount: 2
          labels: {}
          nodeSelector: {}
          configSource: {}
          additionalCeleryArgs: []

      # Additional environment variables to set on the celery/job containers
      # A Kubernetes ConfigMap will be created with these environment variables. See:
      # https://kubernetes.io/docs/concepts/configuration/configmap/
      #
      # Example:
      #
      # env:
      #   ENV_ONE: one
      #   ENV_TWO: two
      env: {}

      # Additional environment variables can be retrieved and set from ConfigMaps. See:
      # https://kubernetes.io/docs/tasks/configure-pod-container/configure-pod-configmap/#configure-all-key-value-pairs-in-a-configmap-as-container-environment-variables
      #
      # Example:
      #
      # envConfigMaps:
      #   - name: config-map
      envConfigMaps: []

      # Additional environment variables can be retrieved and set from Secrets. See:
      # https://kubernetes.io/docs/concepts/configuration/secret/#use-case-as-container-environment-variables
      #
      # Example:
      #
      # envSecrets:
      #   - name: secret
      envSecrets: []

      annotations: {}

      # Sets a node selector as a default for all Celery queues.
      #
      # See:
      # https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector
      nodeSelector: {}

      # Support affinity and tolerations for Celery pod assignment. See:
      # https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity
      # https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/
      affinity: {}
      tolerations: []
      podSecurityContext: {}
      securityContext: {}

      # Specify resources.
      # Example:
      #
      # resources:
      #   limits:
      #     cpu: 100m
      #     memory: 128Mi
      #   requests:
      #     cpu: 100m
      #     memory: 128Mi
      resources: {}

      # Override the default K8s scheduler
      # schedulerName: ~

      # If `livenessProbe` does not contain `exec` field, then we will default to using:
      # exec:
      #   command:
      #     - /bin/sh
      #     - -c
      #     - dagster-celery status -A dagster_celery_k8s.app -y {{ $.Values.global.dagsterHome }}/celery-config.yaml | grep "${HOSTNAME}:.*OK"
      livenessProbe:
        initialDelaySeconds: 15
        periodSeconds: 10
        timeoutSeconds: 10
        successThreshold: 1
        failureThreshold: 3

      # Additional volumes that should be included in the Job's Pod. See:
      # https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volume-v1-core
      #
      # Example:
      #
      # volumes:
      #   - name: my-volume
      #     configMap: my-config-map
      volumes:
        - name: imqcam-local-data
          persistentVolumeClaim:
            claimName: imqcam-local-data

      # Additional volume mounts that should be included in the container in the Job's Pod. See:
      # See: https://v1-18.docs.kubernetes.io/docs/reference/generated/kubernetes-api/v1.18/#volumemount-v1-core
      #
      # Example:
      #
      # volumeMounts:
      #   - name: test-volume
      #     mountPath: /opt/dagster/test_folder
      #     subPath: test_file.yaml
      volumeMounts:
        - name: imqcam-local-data
          mountPath: /tmp/imqcam_filesystem_io_data

      # Additional labels that should be included in the Job's Pod. See:
      # https://kubernetes.io/docs/concepts/overview/working-with-objects/labels
      #
      # Example:
      # labels:
      #   my_label_key: my_label_value
      labels: {}

      # Whether the launched Kubernetes Jobs and Pods should fail if the Dagster run fails.
      failPodOnRunFailure: false

####################################################################################################
# RabbitMQ: Configuration values for rabbitmq. Only one of RabbitMQ / Redis should be enabled.
####################################################################################################
rabbitmq:
  enabled: true

  image:
    repository: "bitnami/rabbitmq"
    tag: "3.8.12"
    pullPolicy: IfNotPresent

  rabbitmq:
    username: test
    password: test

  service:
    port: 5672

  # https://github.com/helm/charts/issues/17250#issuecomment-533444837
  volumePermissions:
    enabled: true
    image:
      repository: bitnami/minideb
      tag: stretch
      pullPolicy: IfNotPresent